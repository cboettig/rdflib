---
title: Data Lake RDF
output: github_document
---

```{r include=FALSE}
knitr::opts_chunk$set(message=FALSE, warning = FALSE)
```

```{r libraries}
library(nycflights13)
library(tidyverse)
library(rdflib)

## experimental methods
source(system.file("examples/as_rdf.R", package="rdflib"))
```

```{r options}
#options(rdflib_storage = "BDB") ## may also be much slower...
options(rdflib_storage = "memory") 
```



```{r}
# Use a smaller dataset if we do not have a BDB backend: 
if(getOption("rdflib_storage") != "BDB"){
flights <- flights %>% 
  filter(distance > 2600) # try smaller dataset
}
```



## Tidyverse Style

Operations in `dplyr` on the `nyflights13` dataset are easy to write and fast to execute

```{r tidyverse}
df <- flights %>% 
  left_join(airlines) %>%
  left_join(planes, by="tailnum") %>% 
  select(carrier, name, manufacturer, model) %>% 
  distinct()
head(df)
```

## RDF Data Lake

In RDF, we simply toss all of our data into the triplestore, or to use a more evocative metaphor, the "Data Lake."  We can then extract whatever tabular structure we need
by querying the data lake using SPARQL, something sometimes referred to as "schema-on-read,"
since we are specifying the desired format of the data when we pull it out of the lake.

This can serve as a very effective means of data integration (provided a reasonably conistent and dilgent use of URIs in identifying subjects and properties (predicates)), since just about any data can be added to the lake without worrying about whether it comes in a schema that matches the existing architecture of the database.  It is this flexibility not to have to define your database schema at the start that is the primary strength of the RDF approach.  

Okay, let's dump the `nyflights13` into the data lake. First, the foreign keys in any table must be represented as URIs and not literal strings: 

```{r}
as_uri <- function(x, base_uri = "x:") paste0(base_uri, x)
uri_flights <- flights %>% 
  mutate(tailnum = as_uri(tailnum),
         carrier = as_uri(carrier))
```


Similiarly, when reading into RDF we have to declare the key column for the table,
and again establish a `base_uri` which will allow RDF methods to distinguish between URIs (subjects, predicates, and foreign keys) and literal strings.  

```{r write_rdf, results='hide', message=FALSE, warning=FALSE}
system.time(
  
rdf <- c(
  as_rdf(airlines, "carrier", "x:"),
  as_rdf(planes,  "tailnum", "x:"),
  as_rdf(uri_flights, NULL, "x:"))

)
```

Note that flights does not have a natural key (somewhat surprisingly, `flight` number is not a unique key for this table, as the same flight number is reused on the same route at different times.)  So, we will treat each row as a unique anonymous key by setting the key to `NULL`.

## Schema on read

We simply define the columns we want and we immediately get back the desired `data.frame`:


```{r query}
s <- 
  'SELECT  ?carrier ?name ?manufacturer ?model ?dep_delay
WHERE {
?flight <x:tailnum>  ?tailnum .
?flight <x:carrier>  ?carrier .
?flight <x:dep_delay>  ?dep_delay .
?tailnum <x:manufacturer> ?manufacturer .
?tailnum <x:model> ?model .
?carrier <x:name> ?name
}'

system.time(
df <- rdf_query(rdf, s)
)

head(df)
```

Note that in place of joins, we give more semantically meaningful statements about the data:
e.g. `manufacturer` is a property of a `tailnum` (corresponding to a particular physical aircraft), not of a `flight` number.  Departure delay `dep_delay` is a property of a flight, not of an aircraft (`tailnum`).  

This is reminiscent of  the way in which these data are organized in the relational database tables to begin with: we find `deb_delay` in the `flights` table and `manufacturer` in the `planes` table. Good relational design encourages this, but to work with the data the user is often left having to do the required joins, which also creates tables where these semantics are less clear.  

Tabular formats can often be sloppy about what is a key and what is a literal value, and also whether a column with the same name in different tables means the same thing in both.  Both of these things pose challenges for later use when joining data.  RDF representation encourages greater discipline through the use of URIs (though we've run a bit roughshod over that with the cavilier use of `x:` here.)

## Non-tabular data

```{r}
f <- system.file("extdata/gh_repos.json", package="repurrrsive")
gh_data <- jsonlite::read_json(f)
```

## Tidyverse style

```{r}
gh_flat <- gh_data %>% flatten()  # abandon nested structure and hope we didn't need it

gh_tibble <- tibble(
  name =     gh_flat %>% map_chr("name"),
  issues =   gh_flat %>% map_int("open_issues_count"),
  wiki =     gh_flat %>% map_lgl("has_wiki"),
  homepage = gh_flat %>% map_chr("homepage", .default = ""),
  owner =    gh_flat %>% map_chr(c("owner", "login"))
)

gh_tibble %>% arrange(name) %>% head()
```

## RDF on non-tabular data

```{r gh_add}
gh_rdf <- as_rdf.list(gh_data, '"@vocab": "gh:"')
```


We can add it to the lake just for kicks:

```{r}
system.time(
rdf <- c(rdf, gh_rdf)
)
```


And we can query it back out of the lake

```{r gh_query}
s <- 
  'SELECT ?name ?issues ?wiki ?homepage ?owner
WHERE {
?repo <gh:homepage>  ?homepage .
?repo <gh:has_wiki> ?wiki .
?repo <gh:open_issues_count> ?issues .
?repo <gh:name> ?name .
?repo <gh:owner> ?owner_id .
?owner_id <gh:login>  ?owner 
}'

system.time(
rdf_tibble <- rdf_query(rdf, s)
)

head(rdf_tibble)
```


